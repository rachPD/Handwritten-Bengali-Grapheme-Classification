{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Bengali_handwritten_grapheme_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aLnH77lxuKHS"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19899295f6074d3c8ba067f4c6bb60f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba6c3b483d1c4bba8af837cef74dc5ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_771e78a5f4ad48a8a0e50dfbe925e957",
              "IPY_MODEL_560b0b15a9ac4734acdca1bfa70177be"
            ]
          }
        },
        "ba6c3b483d1c4bba8af837cef74dc5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "771e78a5f4ad48a8a0e50dfbe925e957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_357d8761d49c410a9e6a6ed208e2482f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 49388949,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49388949,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d54785b18cca4c66b314571d204989a7"
          }
        },
        "560b0b15a9ac4734acdca1bfa70177be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00dec352d48440d098fdc3ded320f994",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 47.1M/47.1M [00:01&lt;00:00, 29.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2a621062a67483798e3aa7d7f8a12e8"
          }
        },
        "357d8761d49c410a9e6a6ed208e2482f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d54785b18cca4c66b314571d204989a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00dec352d48440d098fdc3ded320f994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2a621062a67483798e3aa7d7f8a12e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6f261645b99433d888c9f04fc2db8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40f144d1a5da4a08ab1e889d2965e185",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65949bb21cf94e64842cf943a7d036ff",
              "IPY_MODEL_b5b4ad77b64c46edb351fead556c8d9c"
            ]
          }
        },
        "40f144d1a5da4a08ab1e889d2965e185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65949bb21cf94e64842cf943a7d036ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67cf2dcad1bf4bb39b0b9c9c4f284098",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8852ab0cb1f744509fcd7d376e249fe6"
          }
        },
        "b5b4ad77b64c46edb351fead556c8d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9bd4d653009f4ea3959566fa519e01a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 97.8M/97.8M [00:00&lt;00:00, 250MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b137eb27b4b495caf8e973be086bb21"
          }
        },
        "67cf2dcad1bf4bb39b0b9c9c4f284098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8852ab0cb1f744509fcd7d376e249fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bd4d653009f4ea3959566fa519e01a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b137eb27b4b495caf8e973be086bb21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a87f04cc877946348866cc2609d8758c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5a09d6e145c4c8dba5b99bbeff4415e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0a5389affce44d26b8a39a7df5a4eddf",
              "IPY_MODEL_7d192d44e696488d80ec951cc59f2643"
            ]
          }
        },
        "e5a09d6e145c4c8dba5b99bbeff4415e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a5389affce44d26b8a39a7df5a4eddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_99b664e9c51e4a6692dbb52fa18797e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 12540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 128,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44a200cec2824dc1a82ce103e08382df"
          }
        },
        "7d192d44e696488d80ec951cc59f2643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bdf22a4f61f467f8c8f52d056d8c164",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  1% 128/12540 [00:21&lt;33:01,  6.26it/s, loss=1.72]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adafe2e08c714afc8a70f5889b60816f"
          }
        },
        "99b664e9c51e4a6692dbb52fa18797e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44a200cec2824dc1a82ce103e08382df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bdf22a4f61f467f8c8f52d056d8c164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "adafe2e08c714afc8a70f5889b60816f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachPD/Handwritten-Bengali-Grapheme-Classification/blob/main/Bengali_handwritten_grapheme_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BF2Lo-ZAu-_"
      },
      "source": [
        "#KAGGLE reqs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoh1mcRZRmo7",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "04d5437b-553f-4aa9-82a4-6a5665e1a867"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload()  #upload kaggle.json file\n",
        "# !pip install -q kaggle\n",
        "# !pip install --upgrade kaggle\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f5f9915a-523a-4325-88ba-9fbf644f6019\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f5f9915a-523a-4325-88ba-9fbf644f6019\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Requirement already up-to-date: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C1BG6xO2RKD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1a46f672-d365-4a8e-f561-24a4a5f5e3d0"
      },
      "source": [
        "!kaggle datasets download -d chefpr7/resnet50ori"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading resnet50ori.zip to /content\n",
            " 92% 225M/245M [00:06<00:00, 26.6MB/s]\n",
            "100% 245M/245M [00:06<00:00, 41.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRQxJM-BUTVh"
      },
      "source": [
        "!mv '/content/drive/My Drive/resnet50bengai.pth' '/content/drive/My Drive/resnet50'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMTycbNESzsZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cc4f2b6f-a2bc-49e1-9746-991ad987330c"
      },
      "source": [
        "!kaggle datasets init -p /content/drive/My\\ Drive/resnet50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data package template written to: /content/drive/My Drive/resnet50/dataset-metadata.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqn0K-ZwVSLM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "8f815cb9-b523-48dd-ed80-988745c71b96"
      },
      "source": [
        "!kaggle datasets create -p /content/drive/My\\ Drive/resnet50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting upload for file resnet50bengai.pth\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 183M/183M [00:06<00:00, 30.3MB/s]\n",
            "Upload successful: resnet50bengai.pth (183MB)\n",
            "Starting upload for file resnet50NEW.pth\n",
            "100% 126M/126M [00:03<00:00, 37.0MB/s]\n",
            "Upload successful: resnet50NEW.pth (126MB)\n",
            "Your private Dataset is being created. Please check progress at https://www.kaggle.com/chefpr7/effnb3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8cWF0PYuQLX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "39b15e92-1bc2-46d8-fb1e-f8380d011201"
      },
      "source": [
        "!pip install pretrainedmodels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pretrainedmodels\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 22.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 29.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.5.0)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.17.5)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60962 sha256=f51878815931495ecf827aa2ec46a4cc4d443533f4261b22b676fd0fe71e38ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBh15v22A8Dn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4T0HLeEA3Ys"
      },
      "source": [
        "#mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n5ocrdRA3Ci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "e01f7a01-1b92-491c-f6ce-7385f3cf17af"
      },
      "source": [
        "!wget "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-18 14:21:23--  https://he-s3.s3.amazonaws.com/media/hackathon/hackerearth-deep-learning-challenge-auto-tag-images-gala/auto-tag-images-of-the-gala-9e47fb31/9d34462453e311ea.zip?Signature=p9H6GHy%2B%2BZ%2Bzhfz4YWZVUwwDgRo%3D\n",
            "Resolving he-s3.s3.amazonaws.com (he-s3.s3.amazonaws.com)... 52.219.32.144\n",
            "Connecting to he-s3.s3.amazonaws.com (he-s3.s3.amazonaws.com)|52.219.32.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 403 Forbidden\n",
            "2020-03-18 14:21:23 ERROR 403: Forbidden.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vwkwe4EuRut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4ffc252a-0767-4fb9-92a2-b26ea864aa3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joDDcIdgwMvt"
      },
      "source": [
        "!unzip -qq '/content/drive/My Drive/bengali.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz9yB_po3PbK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "4824ce6d-beb7-410a-bb94-200c64d5c564"
      },
      "source": [
        "!git clone https://github.com/RobinSmits/KaggleBengaliAIHandwrittenGraphemeClassification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'KaggleBengaliAIHandwrittenGraphemeClassification'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects:   6% (1/15)\u001b[K\rremote: Counting objects:  13% (2/15)\u001b[K\rremote: Counting objects:  20% (3/15)\u001b[K\rremote: Counting objects:  26% (4/15)\u001b[K\rremote: Counting objects:  33% (5/15)\u001b[K\rremote: Counting objects:  40% (6/15)\u001b[K\rremote: Counting objects:  46% (7/15)\u001b[K\rremote: Counting objects:  53% (8/15)\u001b[K\rremote: Counting objects:  60% (9/15)\u001b[K\rremote: Counting objects:  66% (10/15)\u001b[K\rremote: Counting objects:  73% (11/15)\u001b[K\rremote: Counting objects:  80% (12/15)\u001b[K\rremote: Counting objects:  86% (13/15)\u001b[K\rremote: Counting objects:  93% (14/15)\u001b[K\rremote: Counting objects: 100% (15/15)\u001b[K\rremote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 32 (delta 4), reused 14 (delta 4), pack-reused 17\u001b[K\n",
            "Unpacking objects: 100% (32/32), done.\n",
            "Checking out files: 100% (14/14), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60tHZY8Yj38o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "a9d9edb0-f7a0-4107-8d43-4e4008db08e7"
      },
      "source": [
        "#For using cutmix \n",
        "! pip install git+https://github.com/ildoonet/cutmix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ildoonet/cutmix\n",
            "  Cloning https://github.com/ildoonet/cutmix to /tmp/pip-req-build-acv8rp99\n",
            "  Running command git clone -q https://github.com/ildoonet/cutmix /tmp/pip-req-build-acv8rp99\n",
            "Building wheels for collected packages: cutmix\n",
            "  Building wheel for cutmix (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cutmix: filename=cutmix-0.1-cp36-none-any.whl size=3602 sha256=5a9f4f4dd9c6eb3116681345e021b09334002eb784efde27fc46a706b5af141d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-amp3y332/wheels/8a/40/20/615302921d0fef73e55b17b5dd57169d4879dfe6dd7ad8ff50\n",
            "Successfully built cutmix\n",
            "Installing collected packages: cutmix\n",
            "Successfully installed cutmix-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB3W7a1QCZBz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "4e9972b6-aa6e-4d2c-c22b-c41df808ba7b"
      },
      "source": [
        "#for using efficientnet models in pytorch \n",
        "!pip install efficientnet_pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.4.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12422 sha256=5f2d8ea78f57076d7408ff7b4ae4564e960199cf0d9bc9ac99ed0d4cf29fae45\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61vDDhQKuKGV"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pdb\n",
        "import time\n",
        "import copy\n",
        "import warnings\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import DataLoader, Dataset, sampler\n",
        "from matplotlib import pyplot as plt\n",
        "from albumentations import (HorizontalFlip,VerticalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise,RandomRotate90,Transpose,RandomBrightnessContrast,RandomCrop)\n",
        "from albumentations.pytorch import ToTensor\n",
        "import albumentations as albu\n",
        "import matplotlib.image as mpi\n",
        "#import segmentation_models_pytorch as smp\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import recall_score\n",
        "import gc\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "seed = 69\n",
        "random.seed(seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "#from cutmix.cutmix import CutMix                                     #INCLUDE THIS FOR USING CUTMIX AUGMENTATION IN PYTORCH \n",
        "#from cutmix.utils import CutMixCrossEntropyLoss                      #INCLUDE THIS FOR USING CUTMIX AUGMENTATION IN PYTORCH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbuPUfCrNBn6"
      },
      "source": [
        "##PREPARING DATA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZpzhgiEuKGa"
      },
      "source": [
        "datadir = Path('bengali_ai')\n",
        "featherdir = Path('bengaliaifeather')\n",
        "outdir = Path('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHxtTwxiNFvf"
      },
      "source": [
        "CONVERTING IMAGES FILES FROM FEATHER FORMAT(BINARY VECTORS) TO .JPG FILES "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utm8kYZPuKGd"
      },
      "source": [
        "def prepare_image(datadir, featherdir, data_type='train',\n",
        "                  submission=False, indices=[0, 1, 2, 3]):\n",
        "    assert data_type in ['train', 'test']\n",
        "    if submission:\n",
        "        image_df_list = [pd.read_parquet(datadir / f'{data_type}_image_data_{i}.parquet')\n",
        "                         for i in indices]\n",
        "    else:\n",
        "        image_df_list = [pd.read_feather(featherdir / f'{data_type}_image_data_{i}.feather')\n",
        "                         for i in tqdm(indices)]\n",
        "\n",
        "    print('image_df_list', len(image_df_list))\n",
        "    HEIGHT = 137\n",
        "    WIDTH = 236\n",
        "    for df in tqdm(image_df_list):\n",
        "        for i in tqdm(range(len(df))):\n",
        "            images = df.iloc[i]\n",
        "            image = images.iloc[1:].values\n",
        "            name = images.iloc[0]\n",
        "            path = os.path.join(\"bengali_images\",name+\".jpg\")\n",
        "            image = image.reshape(137,236).astype(np.uint8)\n",
        "            cv2.imwrite(path,image)\n",
        "            \n",
        "           \n",
        "    #images = [df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH) for df in image_df_list]\n",
        "    del image_df_list\n",
        "    gc.collect()\n",
        "    #images = np.concatenate(images, axis=0)\n",
        "    return height\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-eqUB_vuKGf"
      },
      "source": [
        "debug = False\n",
        "train = pd.read_csv(datadir/'train.csv')\n",
        "train_labels = train[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
        "indices = [0] if debug else [0, 1, 2, 3]\n",
        "train_images = prepare_image(\n",
        "    datadir, featherdir, data_type='train', submission=False, indices=indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2h99KZkuKGh"
      },
      "source": [
        "model = EfficientNet.from_name('efficientnet-b0')\n",
        "in_features = model._fc.in_features\n",
        "model._fc = nn.Linear(in_features,7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoxblp7QuKGk"
      },
      "source": [
        "model2 = EfficientNet.from_name('efficientnet-b0')\n",
        "in_features = model2._fc.in_features\n",
        "model2._fc = nn.Linear(in_features,11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRnS44oUuKGn"
      },
      "source": [
        "model3 = EfficientNet.from_name('efficientnet-b3')\n",
        "in_features = model3._fc.in_features\n",
        "model3._fc = nn.Linear(in_features,168)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1DQzSemuKGq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "19899295f6074d3c8ba067f4c6bb60f0",
            "ba6c3b483d1c4bba8af837cef74dc5ff",
            "771e78a5f4ad48a8a0e50dfbe925e957",
            "560b0b15a9ac4734acdca1bfa70177be",
            "357d8761d49c410a9e6a6ed208e2482f",
            "d54785b18cca4c66b314571d204989a7",
            "00dec352d48440d098fdc3ded320f994",
            "e2a621062a67483798e3aa7d7f8a12e8"
          ]
        },
        "outputId": "9b88158c-059a-43fa-af5c-f87b7aade55e"
      },
      "source": [
        "model = EfficientNet.from_pretrained('efficientnet-b3',num_classes=186)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to /root/.cache/torch/checkpoints/efficientnet-b3-5fb5a3c3.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19899295f6074d3c8ba067f4c6bb60f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=49388949), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV_icnOLws92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "c6f261645b99433d888c9f04fc2db8f2",
            "40f144d1a5da4a08ab1e889d2965e185",
            "65949bb21cf94e64842cf943a7d036ff",
            "b5b4ad77b64c46edb351fead556c8d9c",
            "67cf2dcad1bf4bb39b0b9c9c4f284098",
            "8852ab0cb1f744509fcd7d376e249fe6",
            "9bd4d653009f4ea3959566fa519e01a6",
            "2b137eb27b4b495caf8e973be086bb21"
          ]
        },
        "outputId": "850a7995-567f-4238-e907-1b19e33e1027"
      },
      "source": [
        "import pretrainedmodels\n",
        "model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
        "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6f261645b99433d888c9f04fc2db8f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=102502400), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPA7CtJTuKGt"
      },
      "source": [
        "in_features = model.last_linear.in_features\n",
        "model.last_linear = nn.Linear(in_features,186)\n",
        "#model._fc.requires_grad = False\n",
        "#model._fc.bias.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZo6pM_quKGw"
      },
      "source": [
        "ckpt_path = \"consonant_modelx.pth\"\n",
        "ckpt_path2 = \"vowel_diactric.pth\"\n",
        "ckpt_path3 = \"final_grapheme.pth\"\n",
        "device = torch.device(\"cuda\")\n",
        "#model = smp.Unet(\"resnet18\", encoder_weights=None, classes=4, activation=None)\n",
        "model.to(device)\n",
        "model2.to(device)\n",
        "model3.to(device)\n",
        "#model.eval()\n",
        "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
        "state2 = torch.load(ckpt_path2, map_location=lambda storage, loc: storage)\n",
        "state3 = torch.load(ckpt_path3, map_location=lambda storage, loc: storage)\n",
        "model.load_state_dict(state[\"state_dict\"])\n",
        "model2.load_state_dict(state2[\"state_dict\"])\n",
        "model3.load_state_dict(state3[\"state_dict\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyZbumUf4N37"
      },
      "source": [
        "import PIL\n",
        "def threshold_image(img):\n",
        "    '''\n",
        "    Helper function for thresholding the images\n",
        "    '''\n",
        "    gray = PIL.Image.fromarray(np.uint8(img), 'L')\n",
        "    ret,th = cv.threshold(np.array(gray),0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
        "    return th\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANqbhI265otP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "5830aabf-3924-4e69-ea92-5bee76f522d5"
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "img=cv2.imread( os.path.join('bengali_images/',df[\"image_id\"].iloc[4]+'.jpg'),0)\n",
        "_,img = cv2.threshold(np.array(img),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "plt.imshow(img,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f082de03a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAADlCAYAAACoGbcCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAR4UlEQVR4nO3df6xkZ13H8ffH1qKisS29aepusVU3\nmmIUyE2twRi1/ihI3JoYUmJ01SYbk6ooJlLkD/xT4w/URElWW1kNoRKEtDH4o1YM8Q8qt1BLf1C6\nFLG7abvX8DOYiNWvf8y5Mtze2Tt3zsydM8+8X8nNnTnnzJxnn55+5rnf85wzqSokSW35imU3QJI0\nf4a7JDXIcJekBhnuktQgw12SGmS4S1KDFhbuSW5K8niSM0luX9R+JEnPl0XMc09yEfAx4IeAs8AH\ngddW1aNz35kk6XkWNXK/HjhTVU9W1ReBu4DjC9qXJGmXixf0vkeAp8aenwW+a9LGV1xxRV1zzTUL\naooktemBBx74j6ra2GvdosJ9X0lOAicBXvziF7O1tbWspkjSSkryyUnrFlWWOQdcPfb8aLfs/1XV\nqararKrNjY09P3gkSTNaVLh/EDiW5NoklwC3APcsaF+SpF0WUpapqueS/ALwd8BFwJ1V9cgi9iVJ\ner6F1dyr6r3Aexf1/pKkybxCVZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12S\nGmS4S1KDDHepAUmW3QQNzNLu5y6pn92BPv58EV+fqdXiyF2SGmS4S1KDDHdJapDhLkkNMtwlqUHO\nlpFWjNMeNQ1H7tKKqap9pzoO9QMgyWDb1hrDXZIaNHO4J7k6yfuSPJrkkSSv65ZfnuTeJE90vy+b\nX3OlYdgZgV7oRyP2yXL0Gbk/B/xqVV0H3ADcluQ64Hbgvqo6BtzXPZeaMW1IGWb2wTLNHO5V9XRV\nfah7/HngMeAIcBw43W12Gri5byOlIZhl9LmIEeu077ns0fJe+57mfIHmYy419yTXAC8D7geurKqn\nu1XPAFfOYx+SpOn1DvckXwv8FfDLVfW58XU1+oje82M6yckkW0m2tre3+zZDWoih1YuH0o4LGVJ/\nrbNe4Z7kKxkF+9ur6t3d4meTXNWtvwo4v9drq+pUVW1W1ebGxkafZkgLMW1A7ZQaLlRumEfYzfoe\nh/kBdaF9WI45XH1mywS4A3isqn5vbNU9wInu8Qng7tmbJ0maRZ8rVF8B/BTwkSQPdst+HfhN4J1J\nbgU+CbymXxOlkYOMpA97X4scFc/zvZM4gl4TM4d7Vf0zMOmou3HW95V2m2WGyrhpw6zPh8c0IT9L\nsC7iQ+Owv9TDD5Pl8ApVSWqQNw7ToM37ROReo8h1ntkxrzLNpD501L48hrsGaZrAHQ+Og1w1Osvr\nLvQeu9u0X2lmZ7v99jFJ3/ZrPRjuGpyDBvtez9ch9Pb7N057snfaD5xZ26HlsOYuSQ0y3DUo04xG\n51XH7TPiXORFQfN+33nPFpr3frUYhruadFjBctgliVn/Xd6wa/0Y7pLUIE+oahBmOYm6yH2tgv1m\n5sziICdXW+nHVhnuGrw+pYgdLQbRLP+maT8Q+sx/t/wzDJZlJKlBhruW7jBuE9vKCcV53BemhX7Q\n/gx3aQ1N82E3zZW2Gi5r7tJADDEw+169quVx5C5JDXLkrqU5zK9kG9KXbwzJIqZTahgcuUud8Q+U\noZYhljW98zC/BUvzYbhLUoMMd6kz69fzLYvTRHUhvcM9yUVJPpzkr7vn1ya5P8mZJH+Z5JL+zZQO\n39Br0Yd9F8edO2EOvV80Mo+R++uAx8ae/xbwlqr6FuDTwK1z2Ick6QB6hXuSo8CPAn/aPQ/wA8C7\nuk1OAzf32YfWz7JKBIex33mWQCyl6EL6jtx/H/g14H+75y8CPlNVz3XPzwJHeu5DDRriTI/dDjM8\nZ7kr5iL60Pp7O2YO9ySvBs5X1QMzvv5kkq0kW9vb27M2Q+ptKN/uNCQG/OrrM3J/BfBjSf4NuItR\nOeYPgEuT7FwcdRQ4t9eLq+pUVW1W1ebGxkaPZkiSdps53KvqjVV1tKquAW4B/rGqfhJ4H/AT3WYn\ngLt7t1JqwKqNhletvfpyi5jn/gbg9UnOMKrB37GAfahRQwuUda9Br/u/f5XN5d4yVfVPwD91j58E\nrp/H+0qSZuONw3SohnbCsc89zad5/TJ5u9715u0HtNbm9WGz35Wb+wXshdYPoTSy7P3r4Ax3aSCm\nDfEh3wJgqO1aR4a7JDXIcJcmGOoodFllmiGUhzQ9T6hKM5j2SzMMQy2LI3dJapDhrubNMnoeymjc\nkb9mZVlGa298PvhB6+xD+RAY0v6dXz8MjtwlqUGO3LUWdkaRFxppH+Rq1EXOpJnlL4i9OIJeb4a7\n1sqswXmQgJxHmA4xkIc6NVR7syyjtXOQ+dp7bTuUkBviB8C4ofTTujLcJalBlmWkCQ77O1THzwtM\nc45AuhDDXWvroOE9bdDOGsjjrzPU1ZdlGUlqkOGuQ7XfycyhjliH2q6hs9+Wx7KMdAGGk1ZVr5F7\nkkuTvCvJR5M8luS7k1ye5N4kT3S/L5tXYyVJ0+lblvkD4G+r6tuA7wQeA24H7quqY8B93XNpakMZ\nLS/6KtR5/ki7zRzuSb4e+F7gDoCq+mJVfQY4DpzuNjsN3Ny3kWpPq4FkGD/fkL8WsGV9Ru7XAtvA\nnyX5cJI/TfJC4Mqqerrb5hngyr6N1PoZQiBME8JDCetVPEmtxeoT7hcDLwfeWlUvA77ArhJMjY64\nPY+6JCeTbCXZ2t7e7tEMSdJufcL9LHC2qu7vnr+LUdg/m+QqgO73+b1eXFWnqmqzqjY3NjZ6NENa\nnGnLK0MZwUs7Zg73qnoGeCrJt3aLbgQeBe4BTnTLTgB392qhmmUgrg5LO6un7zz3XwTenuQS4Eng\nZxl9YLwzya3AJ4HX9NyHJOmAeoV7VT0IbO6x6sY+7yvtGL+JlqTpefsBLd1+4T2EmTPSqjHcJalB\nhrsGwZOri+VfP+vHcNfKMJwuzA9IjTPcNSjW34fJD43VY7hLUoO8n7sGp6r2HZ23PkVy2r9O9uqD\nC/Vf6/2mLzHctbJaCqp5fO/qjkX1iV/avVosy0hSgxy5a5CmHSXurF/FEfyiRsCLHllPUzbbvb0O\nnyN3Ddq0wbAqpYKd2T6r0t5JDOzhM9w1eK3M3x5KoA+lHVosw12SGmTNXStjv1rvkOvv86xRD2Xk\n7eyZYTPctVKmCZQhhfwigm/839V3CuWi+2gI/w3WlWUZSWqQI3etpIOM4Me3P0z7jar7tmko5RBH\n58PkyF0rba8vq95LK1MQx80jVFvqD305w12SGmRZRs0YylWt04yG57XvecxYGdIJaM1Pr5F7kl9J\n8kiSh5O8I8lXJbk2yf1JziT5yySXzKux0jRau6p1Ggazdps53JMcAX4J2KyqbwcuAm4Bfgt4S1V9\nC/Bp4NZ5NFQ6iGUF/DQnURd510ZDXjv61twvBr46ycXA1wBPAz8AvKtbfxq4uec+JEkHNHO4V9U5\n4HeAf2cU6p8FHgA+U1XPdZudBY70baQ0i6HNpDmsUbWjd0G/ssxlwHHgWuAbgBcCNx3g9SeTbCXZ\n2t7enrUZ0lSmLVm0MmXSgFefsswPAp+oqu2q+m/g3cArgEu7Mg3AUeDcXi+uqlNVtVlVmxsbGz2a\nIUnarU+4/ztwQ5KvyWiYcyPwKPA+4Ce6bU4Ad/drojQ/46Wag5RrppleeaFtljGSPugJ1lX/a0Vf\nrk/N/X5GJ04/BHyke69TwBuA1yc5A7wIuGMO7ZQWYtqgh9Ut2ViiWU+9LmKqqjcDb961+Eng+j7v\nK0nqxytUpc7uEe60txUeWjlmL957ff0Y7tIE04T9qoXlQb/cWqvLcJemNGkUblhqiLwrpCQ1yHCX\nFmQo9faDWMXZQNqb4S71sIpBeKEPHW8+1g7DXZIa5AlVaQ05Om+f4S7NmcGpIbAsI0kNMtwlqUGG\nuzRHlmQ0FIa7JDXIcJekBhnuktQgw12awaTL9FfxilW1yXCXpAYZ7pLUIMNdmoE32NLQ7RvuSe5M\ncj7Jw2PLLk9yb5Inut+XdcuT5A+TnEnyUJKXL7LxkqS9TTNyfxtw065ltwP3VdUx4L7uOcArgWPd\nz0ngrfNppiTpIPYN96p6P/CpXYuPA6e7x6eBm8eW/3mNfAC4NMlV82qsJGk6s9bcr6yqp7vHzwBX\ndo+PAE+NbXe2WyY1ybq7hqr3CdUaHd0HPsKTnEyylWRre3u7bzMkSWNmDfdnd8ot3e/z3fJzwNVj\n2x3tlj1PVZ2qqs2q2tzY2JixGdLyjY/eHclrKGYN93uAE93jE8DdY8t/ups1cwPw2bHyjdQsp0Zq\naPb9JqYk7wC+D7giyVngzcBvAu9McivwSeA13ebvBV4FnAH+E/jZBbRZkrSPfcO9ql47YdWNe2xb\nwG19GyVJ6scrVCWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCX\npAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG7RvuSe5Mcj7Jw2PLfjvJR5M8\nlOQ9SS4dW/fGJGeSPJ7kRxbVcEnSZNOM3N8G3LRr2b3At1fVdwAfA94IkOQ64BbgJd1r/jjJRXNr\nrSRpKvuGe1W9H/jUrmV/X1XPdU8/ABztHh8H7qqq/6qqTwBngOvn2F5J0hTmUXP/OeBvusdHgKfG\n1p3tlkmSDlGvcE/yJuA54O0zvPZkkq0kW9vb232aIUnaZeZwT/IzwKuBn6yq6hafA64e2+xot+x5\nqupUVW1W1ebGxsaszZAk7WGmcE9yE/BrwI9V1X+OrboHuCXJC5JcCxwD/qV/MyVJB3HxfhskeQfw\nfcAVSc4Cb2Y0O+YFwL1JAD5QVT9fVY8keSfwKKNyzW1V9T+LarwkaW/5UkVleTY3N2tra2vZzZCk\nlZLkgara3GudV6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDh\nLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDRrEd6gm2Qa+APzHstsyUFdg\n30xi30xm30zWSt98Y1Vt7LViEOEOkGRr0he9rjv7ZjL7ZjL7ZrJ16BvLMpLUIMNdkho0pHA/tewG\nDJh9M5l9M5l9M1nzfTOYmrskaX6GNHKXJM3J0sM9yU1JHk9yJsnty27PsiX5tyQfSfJgkq1u2eVJ\n7k3yRPf7smW38zAkuTPJ+SQPjy3bsy8y8ofdcfRQkpcvr+WLN6FvfiPJue7YeTDJq8bWvbHrm8eT\n/MhyWn04klyd5H1JHk3ySJLXdcvX6thZargnuQj4I+CVwHXAa5Nct8w2DcT3V9VLx6Zq3Q7cV1XH\ngPu65+vgbcBNu5ZN6otXAse6n5PAWw+pjcvyNp7fNwBv6Y6dl1bVewG6/6duAV7SveaPu//3WvUc\n8KtVdR1wA3Bb1wdrdewse+R+PXCmqp6sqi8CdwHHl9ymIToOnO4enwZuXmJbDk1VvR/41K7Fk/ri\nOPDnNfIB4NIkVx1OSw/fhL6Z5DhwV1X9V1V9AjjD6P+9JlXV01X1oe7x54HHgCOs2bGz7HA/Ajw1\n9vxst2ydFfD3SR5IcrJbdmVVPd09fga4cjlNG4RJfeGxNPILXWnhzrHy3dr2TZJrgJcB97Nmx86y\nw13P9z1V9XJGfyreluR7x1fWaHqTU5ywL/bwVuCbgZcCTwO/u9zmLFeSrwX+Cvjlqvrc+Lp1OHaW\nHe7ngKvHnh/tlq2tqjrX/T4PvIfRn8/P7vyZ2P0+v7wWLt2kvlj7Y6mqnq2q/6mq/wX+hC+VXtau\nb5J8JaNgf3tVvbtbvFbHzrLD/YPAsSTXJrmE0Umfe5bcpqVJ8sIkX7fzGPhh4GFGfXKi2+wEcPdy\nWjgIk/riHuCnu5kPNwCfHfsTfC3sqhP/OKNjB0Z9c0uSFyS5ltGJw3857PYdliQB7gAeq6rfG1u1\nXsdOVS31B3gV8DHg48Cblt2eJffFNwH/2v08stMfwIsYnd1/AvgH4PJlt/WQ+uMdjMoL/82oDnrr\npL4Awmjm1ceBjwCby27/EvrmL7p/+0OMAuuqse3f1PXN48Arl93+BffN9zAquTwEPNj9vGrdjh2v\nUJWkBi27LCNJWgDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBv0f5jt53pSr2n4AAAAA\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGokv2S4Nmuh"
      },
      "source": [
        "##DATALOADERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y4VhCTmuKGy"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, df, data_folder, mean, std, phase):\n",
        "        self.df = df\n",
        "        self.root = data_folder\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.phase = phase\n",
        "        self.transforms = get_transforms(phase, mean, std)\n",
        "        self.transforms2 = get_transforms2(mean, std)\n",
        "        self.fnames = self.df.index\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.df[\"image_id\"].iloc[idx]\n",
        "        image_path = os.path.join(self.root,  image_id+'.jpg')\n",
        "        img = cv2.imread(image_path,0)\n",
        "        #print(img.shape)\n",
        "        _ ,img = cv2.threshold(np.array(img),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "        \n",
        "        img = crop_char_image3(255-img)\n",
        "        #print(img.shape)\n",
        "        #img = img.reshape(137,236,1)\n",
        "        img = img.reshape(img.shape[0],img.shape[1],1)\n",
        "        img = np.concatenate([img,img,img],axis=2)\n",
        "    \n",
        "        label = np.asarray(self.df.iloc[idx].iloc[1:]).astype(np.uint8)\n",
        "        augmented = self.transforms(image=img)\n",
        "        imgtf1 = augmented['image']\n",
        "        #aug = self.transforms2(image = img)\n",
        "        #imgtf2 = aug[\"image\"]\n",
        "        #imag2 = imag2.reshape(imag2.shape[0],imag2.shape[1],1)\n",
        "        #imag2 = np.concatenate([imag2,imag2,imag2],axis=2)\n",
        "        #aug = self.transforms(image=imag2)\n",
        "        #imagtf1 = aug['image']\n",
        "        #aug = self.transforms2(image = imag2)\n",
        "        #imagtf2 = aug[\"image\"]\n",
        "        return imgtf1,label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fnames)\n",
        "\n",
        "\n",
        "def get_transforms(phase, mean, std):\n",
        "    list_transforms = []\n",
        "    if phase == 'train':\n",
        "        list_transforms.extend(\n",
        "            [GaussNoise(p=0.2),\n",
        "                   RandomBrightnessContrast(p=0.5),\n",
        "                   ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=10, interpolation=2, border_mode=1, p=1),\n",
        "                   ]\n",
        "        )\n",
        "    list_transforms.extend(\n",
        "        [ \n",
        "            Resize(64,64,interpolation = 2),\n",
        "            Normalize(mean=mean, std=std, p=1),\n",
        "            ToTensor(),\n",
        "        ]\n",
        "    )\n",
        "    list_trfms = Compose(list_transforms)\n",
        "    return list_trfms\n",
        "def get_transforms2( mean, std):\n",
        "    list_transforms = []\n",
        "    list_transforms.extend(\n",
        "        [ \n",
        "            \n",
        "            Resize(224,224,interpolation = 2),\n",
        "            Normalize(mean=mean, std=std, p=1),\n",
        "            ToTensor(),\n",
        "        ]\n",
        "    )\n",
        "    list_trfms = Compose(list_transforms)\n",
        "    return list_trfms\n",
        "def crop_char_image3(image, threshold=80):\n",
        "    assert image.ndim == 2\n",
        "    is_black = image > threshold\n",
        "\n",
        "    is_black_vertical = np.sum(is_black, axis=0) > 0\n",
        "    is_black_horizontal = np.sum(is_black, axis=1) > 0\n",
        "    left = np.argmax(is_black_horizontal)\n",
        "    right = np.argmax(is_black_horizontal[::-1])\n",
        "    top = np.argmax(is_black_vertical)\n",
        "    bottom = np.argmax(is_black_vertical[::-1])\n",
        "    height, width = image.shape\n",
        "    cropped_image = image[left:height - right, top:width - bottom]\n",
        "    return cropped_image\n",
        "\n",
        "def provider(\n",
        "    data_folder,\n",
        "    df_path,\n",
        "    phase,\n",
        "    mean=None,\n",
        "    std=None,\n",
        "    batch_size=8,\n",
        "    num_workers=0,\n",
        "):\n",
        "    '''Returns dataloader for the model training'''\n",
        "    data = pd.read_csv(df_path)\n",
        "\n",
        "    #label = data['grapheme_root']\n",
        "    label3 = data['consonant_diacritic']\n",
        "    label2 = data['vowel_diacritic']\n",
        "    label = data['grapheme_root']\n",
        "    data2 = pd.get_dummies(label)\n",
        "    data3 = pd.get_dummies(label2)\n",
        "    data4 =  pd.get_dummies(label3)\n",
        "    dict={}\n",
        "    for i in range(168):\n",
        "        dict[(i)] = i+1\n",
        "    data2.rename(columns=dict,inplace=True)    \n",
        "    dict2 = {}\n",
        "    for i in range(11):\n",
        "        dict2[(i)] = i+169\n",
        "    data3.rename(columns=dict2,inplace=True)    \n",
        "    dict3= {}\n",
        "    for i in range(7):\n",
        "        dict3[(i)] = i+180\n",
        "    data4.rename(columns=dict3,inplace=True)\n",
        "    \n",
        "    data=data.drop(columns=['grapheme_root','vowel_diacritic','consonant_diacritic','grapheme'])\n",
        "    data=pd.concat([data,data2,data3,data4],axis=1)\n",
        "    train_df, val_df = train_test_split(data, test_size=0.001,stratify=label)\n",
        "    df = train_df if phase == \"train\" else val_df\n",
        "    image_dataset = Dataset(df, data_folder, mean, std, phase)\n",
        "    \n",
        "    #class_sample_counts=np.unique(label, return_counts=True)[1]\n",
        "   # weights = (1 / torch.Tensor(class_prob))\n",
        "   # weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(train_labels))\n",
        "    #train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, sampler=weighted_sampler)\n",
        "    \n",
        "    #dataset = CutMix(image_dataset, num_class=186, beta=1.0, prob=0.5, num_mix=2)\n",
        "    \n",
        "    dataloader = DataLoader(\n",
        "        #dataset,\n",
        "        image_dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=False,\n",
        "        shuffle=True,   \n",
        "    )\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhtO7BUxN-S2"
      },
      "source": [
        "##DEFINING METRICS AND HELPER FUNCTIONS "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyK_qqNzuKG1"
      },
      "source": [
        "bs = 16\n",
        "def predict(X, threshold):\n",
        "    '''X is sigmoid output of the model'''\n",
        "    X_p = np.copy(X)\n",
        "    preds = (X_p > threshold).astype('uint8')\n",
        "    return preds\n",
        "\n",
        "def metric(probs, t, threshold=0.5, reduction='none'):\n",
        "    '''Calculates dice of positive and negative images seperately'''\n",
        "    '''probability and truth must be torch tensors'''\n",
        "    batch_size = len(t)\n",
        "    with torch.no_grad():\n",
        "        #print(probability.shape,probs2.shape,probs3.shape,truth.shape)\n",
        "        #probability = probability.view(batch_size, -1)\n",
        "        #truth = truth.view(batch_size, -1)\n",
        "        t = (t ).float().cpu()\n",
        "        pt = probs[:,:168].argmax(dim=1)\n",
        "        tt = t[:,:168].argmax(dim=1)\n",
        "        pt2 = probs[:,168:179].argmax(dim=1)\n",
        "        tt2 = t[:,168:179].argmax(dim=1)\n",
        "        pt3 = probs[:,179:].argmax(dim=1)\n",
        "        tt3 = t[:,179:].argmax(dim=1)\n",
        "        csum = (pt==tt).sum().float()\n",
        "        acc  = csum/bs\n",
        "        rec_sc=recall_score(tt,pt,average = 'macro')\n",
        "        csum = (pt2==tt2).sum().float()\n",
        "        acc2 = csum/bs\n",
        "        rec_sc2 = recall_score(tt2,pt2,average = 'macro')\n",
        "        csum = (pt3==tt3).sum().float()\n",
        "        acc3 = csum/bs\n",
        "        rec_sc3 = recall_score(tt3,pt3,average = 'macro')\n",
        "\n",
        "        #dice_pos = (2 * (p*t).sum(-1)+1)/(((p+t).sum(-1))+1)\n",
        "        \n",
        "        #p_neg = (p == 0).float()\n",
        "        #t_neg = (t == 0).float()\n",
        "        #dice_neg = (2 * (p_neg*t_neg).sum(-1)+1)/(((p_neg+t_neg).sum(-1))+1)\n",
        "\n",
        "        #dice = torch.cat([dice_pos, dice_neg])\n",
        "\n",
        "        #dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
        "        #dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
        "        #dice = dice.mean().item()\n",
        "\n",
        "\n",
        "    return acc,rec_sc,acc2,rec_sc2,acc3,rec_sc3\n",
        "\n",
        "class Meter:\n",
        "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
        "    def __init__(self, phase, epoch):\n",
        "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
        "        self.phase = phase\n",
        "        self.base_dice_scores = []\n",
        "        self.rec_sc = []\n",
        "        self.base_dice_scores2 = []\n",
        "        self.rec_sc2 = []\n",
        "        self.base_dice_scores3 = []\n",
        "        self.rec_sc3 = []\n",
        "        #self.dice_neg_scores = []\n",
        "        #self.dice_pos_scores = []\n",
        "        #self.iou_scores = []\n",
        "\n",
        "    def update(self, targets, outputs):\n",
        "        #print(outputs.shape)\n",
        "        #probs = torch.softmax(outputs[:,:168],dim=1)\n",
        "        #probs2 = torch.softmax(outputs[:,168:179],dim=1)\n",
        "        #probs3 = torch.softmax(outputs[:,179:],dim=1)\n",
        "        #print(probs,probs.shape)\n",
        "        dice,rec,dice2,rec2,dice3,rec3 = metric(outputs, targets, self.base_threshold)\n",
        "\n",
        "        self.base_dice_scores.append(dice)\n",
        "        self.rec_sc.append(rec)\n",
        "       \n",
        "        self.base_dice_scores2.append(dice2)\n",
        "        self.rec_sc2.append(rec2)\n",
        "        \n",
        "        self.base_dice_scores3.append(dice3)\n",
        "        self.rec_sc3.append(rec3)\n",
        "        #self.dice_pos_scores.append(dice_pos)\n",
        "        #self.dice_neg_scores.append(dice_neg)\n",
        "        #preds = predict(probs, self.base_threshold)\n",
        "        #iou = compute_iou_batch(preds, targets, classes=[1])\n",
        "        #self.iou_scores.append(iou)\n",
        "\n",
        "    def get_metrics(self):\n",
        "        dice = np.mean(self.base_dice_scores)\n",
        "        rec = np.mean(self.rec_sc)\n",
        "        dice2 = np.mean(self.base_dice_scores2)\n",
        "        rec2 = np.mean(self.rec_sc2)\n",
        "        dice3 = np.mean(self.base_dice_scores3)\n",
        "        rec3 = np.mean(self.rec_sc3)\n",
        "        #dice_neg = np.mean(self.dice_neg_scores)\n",
        "        #dice_pos = np.mean(self.dice_pos_scores)\n",
        "        #dices = [dice, dice_neg, dice_pos]\n",
        "        #iou = np.nanmean(self.iou_scores)\n",
        "        return dice,rec,dice2,rec2,dice3,rec3\n",
        "\n",
        "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
        "    '''logging the metrics at the end of an epoch'''\n",
        "    dice,rec,dice2,rec2,dice3,rec3 = meter.get_metrics()\n",
        "    print(\"Loss: %0.4f  | acc: %0.4f  | rec: %0.4f |acc2: %0.4f  | rec2: %0.4f| acc3: %0.4f | rec3: %0.4f\" % (epoch_loss, dice, rec,dice2,rec2,dice3,rec3 ))\n",
        "    return dice,rec,dice2,rec2,dice3,rec3\n",
        "    #dice, dice_neg, dice_pos = dices\n",
        "    #print(\"Loss: %0.4f  | acc: %0.4f  | rec: %0.4f \" % (epoch_loss, dice, rec ))\n",
        "    #return dice,rec\n",
        "\n",
        "def compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n",
        "    '''computes iou for one ground truth mask and predicted mask'''\n",
        "    pred[label == ignore_index] = 0\n",
        "    ious = []\n",
        "    for c in classes:\n",
        "        label_c = label == c\n",
        "        if only_present and np.sum(label_c) == 0:\n",
        "            ious.append(np.nan)\n",
        "            continue\n",
        "        pred_c = pred == c\n",
        "        intersection = np.logical_and(pred_c, label_c).sum()\n",
        "        union = np.logical_or(pred_c, label_c).sum()\n",
        "        if union != 0:\n",
        "            ious.append(intersection / union)\n",
        "    return ious if ious else [1]\n",
        "\n",
        "def compute_iou_batch(outputs, labels, classes=None):\n",
        "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
        "    ious = []\n",
        "    preds = np.copy(outputs) # copy is imp\n",
        "    labels = np.array(labels) # tensor to np\n",
        "    for pred, label in zip(preds, labels):\n",
        "        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n",
        "    iou = np.nanmean(ious)\n",
        "    return iou\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnz3Ja26OMrl"
      },
      "source": [
        "## TRYING A CUSTOM FUNCTION TO SUPPLY CLASS WEIGHTS\n",
        "$weight (class x)$ = $e^(-freq[class i]/freq[most occuring class])$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP0ee1jagaQ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f2faf00c-f164-4e0f-9c05-76885e228b74"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>grapheme_root</th>\n",
              "      <th>vowel_diacritic</th>\n",
              "      <th>consonant_diacritic</th>\n",
              "      <th>grapheme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train_0</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>ক্ট্রো</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Train_1</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>হ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Train_2</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>খ্রী</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Train_3</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>র্টি</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Train_4</td>\n",
              "      <td>71</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>থ্রো</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
              "0  Train_0             15                9                    5   ক্ট্রো\n",
              "1  Train_1            159                0                    0        হ\n",
              "2  Train_2             22                3                    5     খ্রী\n",
              "3  Train_3             53                2                    2     র্টি\n",
              "4  Train_4             71                9                    5     থ্রো"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhR5fYA9gl5T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "293aba3d-3735-4845-8b36-e0da1deab323"
      },
      "source": [
        "df[\"vowel_diacritic\"].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFqSEOG2csBk"
      },
      "source": [
        "df = pd.read_csv('/content/train.csv')\n",
        "df.head()\n",
        "x = df[\"grapheme_root\"].value_counts()\n",
        "gr = [0]*168\n",
        "for i in range(len(x)):\n",
        "    gr[x.index[i]]=x.values[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPbug2U3fBd5"
      },
      "source": [
        "for i in range(len(gr)):\n",
        "    gr[i]=np.exp(-gr[i]/max(gr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sghbK46hD-d"
      },
      "source": [
        "#weights = []\n",
        "#weights.append(gr)\n",
        "#weights.append(vd)\n",
        "#weights.append(cd)\n",
        "#len(weights)\n",
        "gr=torch.Tensor(gr)\n",
        "vd=torch.Tensor(vd)\n",
        "cd=torch.Tensor(cd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Sd-1bylZVA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "190ffe27-617d-4534-a6cd-1cbcb18d40d3"
      },
      "source": [
        "gr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9746979848841162,\n",
              " 0.9750378969939706,\n",
              " 0.9429408314103613,\n",
              " 0.9460694194464112,\n",
              " 0.9439276872401755,\n",
              " 0.9699516388813939,\n",
              " 0.9477202119426896,\n",
              " 0.9736789593785679,\n",
              " 0.9730002009819598,\n",
              " 0.9255141502886863,\n",
              " 0.9738487229487731,\n",
              " 0.9740185161177177,\n",
              " 0.974867926124185,\n",
              " 0.388714808443331,\n",
              " 0.870425885213277,\n",
              " 0.8279458449540238,\n",
              " 0.8488461974472313,\n",
              " 0.8757532982010876,\n",
              " 0.7522450332877768,\n",
              " 0.9526898923094402,\n",
              " 0.9431052357044982,\n",
              " 0.8485502775626753,\n",
              " 0.5967760335728777,\n",
              " 0.40752056665067915,\n",
              " 0.9431052357044982,\n",
              " 0.821619092743351,\n",
              " 0.9706282706215826,\n",
              " 0.9482160111529087,\n",
              " 0.8760587047535993,\n",
              " 0.6159076173894815,\n",
              " 0.9266443026214365,\n",
              " 0.8746852134677378,\n",
              " 0.821619092743351,\n",
              " 0.9765689690119786,\n",
              " 0.9530221294088843,\n",
              " 0.920365267081043,\n",
              " 0.8365059732194667,\n",
              " 0.951527974299331,\n",
              " 0.5572573965639479,\n",
              " 0.8980170284175842,\n",
              " 0.8763642178123182,\n",
              " 0.9482160111529087,\n",
              " 0.7109319801497667,\n",
              " 0.5310786307022247,\n",
              " 0.8317072559321733,\n",
              " 0.9752078974986387,\n",
              " 0.90382839955342,\n",
              " 0.9242242353055946,\n",
              " 0.786715634762185,\n",
              " 0.9455747426370589,\n",
              " 0.8792719109736896,\n",
              " 0.9447508560092037,\n",
              " 0.8495864487280153,\n",
              " 0.5255523683345171,\n",
              " 0.9019395216636579,\n",
              " 0.7461064241097882,\n",
              " 0.625865838177159,\n",
              " 0.89551558984667,\n",
              " 0.7992961829102351,\n",
              " 0.6651282144159246,\n",
              " 0.9284230451747876,\n",
              " 0.9046165990321835,\n",
              " 0.8595683235339298,\n",
              " 0.9743581912724686,\n",
              " 0.376968839966319,\n",
              " 0.7882257768663121,\n",
              " 0.8719446876291901,\n",
              " 0.9205257352642441,\n",
              " 0.895827888218343,\n",
              " 0.8763642178123182,\n",
              " 0.8463341642311969,\n",
              " 0.5993827212937476,\n",
              " 0.36787944117144233,\n",
              " 0.975864535458579,\n",
              " 0.7518001706097062,\n",
              " 0.8091246515215549,\n",
              " 0.6950014249034558,\n",
              " 0.8353926618001812,\n",
              " 0.9464237822721553,\n",
              " 0.5221095524576096,\n",
              " 0.9178712240315358,\n",
              " 0.524075694188411,\n",
              " 0.9466016647605466,\n",
              " 0.7660626982873333,\n",
              " 0.9171814842751406,\n",
              " 0.7740220959124544,\n",
              " 0.6746676701937494,\n",
              " 0.9689202104954587,\n",
              " 0.8669011738269324,\n",
              " 0.6474635846381643,\n",
              " 0.8888427054078896,\n",
              " 0.7488389433508096,\n",
              " 0.8107990693550049,\n",
              " 0.8896783194343766,\n",
              " 0.8328844477764068,\n",
              " 0.8722942639875216,\n",
              " 0.3962278582877947,\n",
              " 0.9135688450143804,\n",
              " 0.8888427054078896,\n",
              " 0.9175262893403567,\n",
              " 0.9192522600307863,\n",
              " 0.8158431419842413,\n",
              " 0.9738492334645805,\n",
              " 0.5218152680769814,\n",
              " 0.9703780551865892,\n",
              " 0.9720207525274753,\n",
              " 0.8683687010916363,\n",
              " 0.36787944117144233,\n",
              " 0.9646885815778243,\n",
              " 0.8133462183287541,\n",
              " 0.9251349135129595,\n",
              " 0.836049780406665,\n",
              " 0.817427782960675,\n",
              " 0.36787944117144233,\n",
              " 0.9664236252289529,\n",
              " 0.40085235442366957,\n",
              " 0.9054969204980539,\n",
              " 0.7056835704610853,\n",
              " 0.7715643861760914,\n",
              " 0.7047201800709344,\n",
              " 0.7597104914044246,\n",
              " 0.9001523458370778,\n",
              " 0.5905863959278403,\n",
              " 0.6237569214162065,\n",
              " 0.6076364582392737,\n",
              " 0.8310134577461178,\n",
              " 0.9644452766365348,\n",
              " 0.8097209686834079,\n",
              " 0.8051249941766734,\n",
              " 0.8003728514080064,\n",
              " 0.9677447783045844,\n",
              " 0.9040548827087707,\n",
              " 0.7893334021071968,\n",
              " 0.3693902375787902,\n",
              " 0.8677524368286014,\n",
              " 0.8649907810328915,\n",
              " 0.7871796970274226,\n",
              " 0.8798886380921611,\n",
              " 0.8084314576876398,\n",
              " 0.5907208799067487,\n",
              " 0.817873697091804,\n",
              " 0.671970402312655,\n",
              " 0.7843172285618483,\n",
              " 0.8705229097619054,\n",
              " 0.8699284933222149,\n",
              " 0.9303664995936423,\n",
              " 0.933549413017214,\n",
              " 0.36787944117144233,\n",
              " 0.5914697293594182,\n",
              " 0.4809009891543989,\n",
              " 0.4944256825370276,\n",
              " 0.6836071709239462,\n",
              " 0.831100484237447,\n",
              " 0.6229236614862502,\n",
              " 0.800032671648397,\n",
              " 0.7536399104626665,\n",
              " 0.7860143341211963,\n",
              " 0.9059688268500278,\n",
              " 0.9573518716933114,\n",
              " 0.36787944117144233,\n",
              " 0.7387179341755225,\n",
              " 0.821835922889092,\n",
              " 0.7457421407801692,\n",
              " 0.9011343265885244,\n",
              " 0.9017030449834045,\n",
              " 0.48650663857855164,\n",
              " 0.8239125760442625,\n",
              " 0.36787944117144233]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBditmiFk4Vx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97c0d7ae-5c6a-43cc-a022-4dead5b6c109"
      },
      "source": [
        "#x = [1,2,3]\n",
        "#y = [4,5,6]\n",
        "#x.append(y)\n",
        "k=[]\n",
        "k.append(x)\n",
        "k.append(y)\n",
        "k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, [4, 5, 6]], [4, 5, 6]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1R92Kk7O946"
      },
      "source": [
        "##TRAINER "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I1QyxehuKG3"
      },
      "source": [
        "class Trainer(object):\n",
        "    '''This class takes care of training and validation of our model'''\n",
        "    def __init__(self, model):\n",
        "        self.num_workers = 0\n",
        "        self.batch_size = {\"train\": 16, \"val\": 16}\n",
        "        self.accumulation_steps = 1\n",
        "        self.lr = 3e-6\n",
        "        self.num_epochs = 15\n",
        "        self.best_loss = float(\"inf\")\n",
        "        self.phases = [\"train\", \"val\"]\n",
        "        self.device = torch.device(\"cuda:0\")\n",
        "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "        self.net = model\n",
        "        #pos_wt = torch.tensor([3.0])\n",
        "        self.criterion1 = torch.nn.BCEWithLogitsLoss(weight=gr)\n",
        "        self.criterion2 = torch.nn.BCEWithLogitsLoss(weight=vd)\n",
        "        self.criterion3 = torch.nn.BCEWithLogitsLoss(weight=cd)\n",
        "        #self.criterion = CutMixCrossEntropyLoss(True)\n",
        "        #self.optimizer = optim.SGD(model.parameters(), lr=self.lr, momentum=0.09)\n",
        "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
        "        \n",
        "        self.scheduler = ReduceLROnPlateau(self.optimizer,factor=0.33, mode=\"min\", patience=3, verbose=True)\n",
        "        self.net = self.net.to(self.device)\n",
        "        cudnn.benchmark = True\n",
        "        \n",
        "        self.dataloaders = {\n",
        "            phase: provider(\n",
        "                data_folder=data_folder,\n",
        "                df_path=train_df_path,\n",
        "                phase=phase,\n",
        "                mean=(0.485, 0.456, 0.406),\n",
        "                std=(0.229, 0.224, 0.225),\n",
        "                batch_size=self.batch_size[phase],\n",
        "                num_workers=self.num_workers,\n",
        "            )\n",
        "            for phase in self.phases\n",
        "        }\n",
        "        self.losses = {phase: [] for phase in self.phases}\n",
        "        self.rec_scores = {phase: [] for phase in self.phases}\n",
        "        self.dice_scores = {phase: [] for phase in self.phases}\n",
        "        self.rec_scores2 = {phase: [] for phase in self.phases}\n",
        "        self.dice_scores2 = {phase: [] for phase in self.phases}\n",
        "        self.rec_scores3 = {phase: [] for phase in self.phases}\n",
        "        self.dice_scores3 = {phase: [] for phase in self.phases}\n",
        "    def forward(self, images, targets):\n",
        "        images = images.to(self.device)\n",
        "        #print(\"targets =\",targets.shape)\n",
        "        #targets = targets.reshape(targets.shape[0],1)\n",
        "        masks = targets.to(self.device)\n",
        "        masks = masks.float()\n",
        "        #masks = masks.reshape(4,1)\n",
        "        outputs = self.net(images)\n",
        "        #rec_sc=recall_score(masks.argmax(dim=1).cpu().numpy(),outputs.argmax(dim=1).cpu().numpy(),average = 'macro') \n",
        "        #print(outputs.type(),masks.type())\n",
        "        #loss = self.criterion(outputs,masks)\n",
        "        loss1 = self.criterion1(outputs[:,:168],masks[:,:168])#+(1-rec_sc)\n",
        "        loss2 = self.criterion2(outputs[:,168:179],masks[:,168:179])\n",
        "        loss3 = self.criterion3(outputs[:,179:],masks[:,179:])\n",
        "        loss = 8*loss1+loss2+loss3\n",
        "        #print(loss,rec_sc)\n",
        "        #loss = self.criterion(outputs.permute(0,2,3,1), masks.permute(0,2,3,1))\n",
        "        '''  after few epochs loss = \"0.25*bce+0.75*dice\"\n",
        "        \n",
        "        d1,d2,d3 = metric(outputs, mask, threshold=0.5, reduction='none')\n",
        "        loss =  0.25*self.criterion(outputs.permute(0,2,3,1), masks.permute(0,2,3,1)) +0.75*(1-d1)\n",
        "        \n",
        "        '''\n",
        "\n",
        "        return loss, outputs\n",
        "\n",
        "    def iterate(self, epoch, phase):\n",
        "        meter = Meter(phase, epoch)\n",
        "        start = time.strftime(\"%H:%M:%S\")\n",
        "        print(f\"Starting epoch: {epoch} | phase: {phase} | ⏰: {start}\")\n",
        "        batch_size = self.batch_size[phase]\n",
        "        self.net.train(phase == \"train\")\n",
        "        dataloader = self.dataloaders[phase]\n",
        "        running_loss = 0.0\n",
        "        total_batches = len(dataloader)\n",
        "        tk0 = tqdm(dataloader, total=total_batches)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        for itr, batch in enumerate(tk0):\n",
        "                   \n",
        "            img1, targets = batch\n",
        "            loss, outputs = self.forward(img1, targets)\n",
        "            #loss2, outputs2 = self.forward(img2, targets)\n",
        "            #loss3, outputs3 = self.forward(img3, targets)\n",
        "            #loss4, outputs4 = self.forward(img4, targets)\n",
        "            \n",
        "            #loss = (loss1+loss2+loss3+loss4)/4\n",
        "            #outputs = (outputs1+outputs2+outputs3+outputs4)/4\n",
        "            \n",
        "            loss = loss / self.accumulation_steps\n",
        "\n",
        "            if phase == \"train\":\n",
        "                loss.backward()\n",
        "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
        "                    self.optimizer.step()\n",
        "                    self.optimizer.zero_grad()\n",
        "            running_loss += loss.item()\n",
        "            outputs = outputs.detach().cpu()\n",
        "            meter.update(targets, outputs)\n",
        "            tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n",
        "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
        "        dice,rec,dice2,rec2,dice3,rec3 = epoch_log(phase, epoch, epoch_loss, meter, start)\n",
        "        self.losses[phase].append(epoch_loss)\n",
        "        self.dice_scores[phase].append(dice)\n",
        "        self.rec_scores[phase].append(rec)\n",
        "        self.dice_scores2[phase].append(dice2)\n",
        "        self.rec_scores2[phase].append(rec2)\n",
        "        self.dice_scores3[phase].append(dice3)\n",
        "        self.rec_scores3[phase].append(rec3)\n",
        "        torch.cuda.empty_cache()\n",
        "        return epoch_loss\n",
        "    def start2(self):\n",
        "        for epoch in range(self.num_epochs):\n",
        "            \n",
        "            val_loss = self.iterate(epoch, \"val\")\n",
        "            self.scheduler.step(val_loss)\n",
        "    def start(self): \n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.iterate(epoch, \"train\")\n",
        "            state = {\n",
        "                \"epoch\": epoch,\n",
        "                \"best_loss\": self.best_loss,\n",
        "                \"state_dict\": self.net.state_dict(),\n",
        "                \"optimizer\": self.optimizer.state_dict(),\n",
        "            }\n",
        "            val_loss = self.iterate(epoch, \"val\")\n",
        "            self.scheduler.step(val_loss)\n",
        "            \n",
        "            if val_loss < self.best_loss:\n",
        "                print(\"******** New optimal found, saving state ********\")\n",
        "                state[\"best_loss\"] = self.best_loss = val_loss\n",
        "                torch.save(state, \"/content/drive/My Drive/resnet50/resnet50NEW.pth\")\n",
        "            print()\n",
        "            np.save(\"logacctrain.npy\",self.dice_scores[\"train\"])\n",
        "            np.save(\"logrectrain.npy\",self.rec_scores[\"train\"])\n",
        "            np.save(\"logaccval.npy\",self.dice_scores[\"val\"])\n",
        "            np.save(\"logrecval.npy\",self.rec_scores[\"val\"])\n",
        "            np.save(\"logacctrain2.npy\",self.dice_scores2[\"train\"])\n",
        "            np.save(\"logrectrain2.npy\",self.rec_scores2[\"train\"])\n",
        "            np.save(\"logaccval2.npy\",self.dice_scores2[\"val\"])\n",
        "            np.save(\"logrecval2.npy\",self.rec_scores2[\"val\"])\n",
        "            np.save(\"logacctrain3.npy\",self.dice_scores3[\"train\"])\n",
        "            np.save(\"logrectrain3.npy\",self.rec_scores3[\"train\"])\n",
        "            np.save(\"logaccval3.npy\",self.dice_scores3[\"val\"])\n",
        "            np.save(\"logrecval3.npy\",self.rec_scores3[\"val\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHnzWGEduKG5"
      },
      "source": [
        "train_df_path = 'train.csv'\n",
        "data_folder = \"bengali_images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3d3xrdouKG8"
      },
      "source": [
        "#model = smp.Unet('resnet18', classes=1, activation=None,encoder_weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqC-MEvZuKHA"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yHTi4ZYfuKHD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a87f04cc877946348866cc2609d8758c",
            "e5a09d6e145c4c8dba5b99bbeff4415e",
            "0a5389affce44d26b8a39a7df5a4eddf",
            "7d192d44e696488d80ec951cc59f2643",
            "99b664e9c51e4a6692dbb52fa18797e8",
            "44a200cec2824dc1a82ce103e08382df",
            "0bdf22a4f61f467f8c8f52d056d8c164",
            "adafe2e08c714afc8a70f5889b60816f"
          ]
        },
        "outputId": "22dfb1d7-1185-41a0-aadf-2b0d060183dc"
      },
      "source": [
        "model_trainer = Trainer(model)\n",
        "model_trainer.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch: 0 | phase: train | ⏰: 23:43:59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a87f04cc877946348866cc2609d8758c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=12540), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdMUA9iZuKHF"
      },
      "source": [
        "scores = [0.9275,0.9676,0.9632]\n",
        "np.average(scores, weights=[2,1,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKIGdsMJ4Jx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "03721f21-50a6-4bd5-bebf-5a14531ba1ff"
      },
      "source": [
        "!unzip /content/resnet50ori.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/resnet50ori.zip\n",
            "  inflating: resnet50bengai.pth      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvMV1Y-VuKHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b38a09c8-3370-4061-996f-0e58179cbf08"
      },
      "source": [
        "ckpt_path = \"/content/drive/My Drive/resnet50/resnet50NEW.pth\"\n",
        "device = torch.device(\"cuda\")\n",
        "#model = smp.Unet(\"resnet18\", encoder_weights=None, classes=4, activation=None)\n",
        "model.to(device)\n",
        "#model.eval()\n",
        "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
        "model.load_state_dict(state[\"state_dict\"])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh7AHnoTuKHJ"
      },
      "source": [
        "def get_transforms2(mean=(0.485, 0.456, 0.406),\n",
        "                std=(0.229, 0.224, 0.225)):\n",
        "    list_transforms = []\n",
        "    \n",
        "    list_transforms.extend(\n",
        "        [ \n",
        "            #HorizontalFlip(),\n",
        "            Resize(224,224,interpolation = 2),\n",
        "            Normalize(mean=mean, std=std, p=1),\n",
        "            ToTensor(),\n",
        "        ]\n",
        "    )\n",
        "    list_trfms = Compose(list_transforms)\n",
        "    return list_trfms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XldWKj6uKHL"
      },
      "source": [
        "import glob\n",
        "filenames = glob.glob('deepfake_frames/test/*.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdbRc_spuKHO"
      },
      "source": [
        "len(filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B6O4JfeuKHQ"
      },
      "source": [
        "fig, axs = plt.subplots(48, 2, figsize=(10, 100))\n",
        "axs = np.array(axs)\n",
        "axs = axs.reshape(-1)\n",
        "model.eval()\n",
        "transforms = get_transforms2()\n",
        "for i,j in enumerate(tqdm(filenames)):\n",
        "    img = mpi.imread(j)\n",
        "    augmented = transforms(image=img)\n",
        "    img2 = augmented['image']\n",
        "    img2=img2.reshape(1,3,img2.shape[1],img2.shape[2])\n",
        "\n",
        "    img2=img2.to(device)\n",
        "    prob = model(img2)\n",
        "    prob = torch.sigmoid(prob)\n",
        "    ax = axs[i]\n",
        "    ax.imshow(img)\n",
        "    ax.grid(False)\n",
        "    ax.title.set_text(str(prob.cpu()))\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.yaxis.set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLnH77lxuKHS"
      },
      "source": [
        "# Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4TuJc_fuKHT"
      },
      "source": [
        "\n",
        "def post_process(probability, threshold, min_size):\n",
        "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
        "    than `min_size` are ignored'''\n",
        "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
        "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
        "    predictions = np.zeros((256, 320), np.int32)\n",
        "    num = 0\n",
        "    for c in range(1, num_component):\n",
        "        p = (component == c)\n",
        "        if p.sum() > min_size:\n",
        "            predictions[p] = 1\n",
        "            num += 1\n",
        "    return predictions, num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYLGzQYRuKHU"
      },
      "source": [
        "def get_transforms2(mean=(0.485, 0.456, 0.406),\n",
        "                std=(0.229, 0.224, 0.225)):\n",
        "    list_transforms = []\n",
        "    list_transforms.extend(\n",
        "        [   Resize(256,320,interpolation=2),\n",
        "            Normalize(mean=mean, std=std, p=1),\n",
        "            ToTensor(),\n",
        "        ]\n",
        "    )\n",
        "    list_trfms = Compose(list_transforms)\n",
        "    return list_trfms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoaxGCbtuKHX"
      },
      "source": [
        "transforms = get_transforms2()\n",
        "\n",
        "img = mpi.imread('file_name.jpg')\n",
        "augmented = transforms(image=img)\n",
        "img = augmented['image']\n",
        "img2=img.reshape(1,3,img.shape[1],img.shape[2])\n",
        "prob = model.predict(img2)\n",
        "prob = torch.sigmoid(prob)\n",
        "prob = prob[0,0].numpy()\n",
        "output,num  = post_process(prob,0.5,200)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}